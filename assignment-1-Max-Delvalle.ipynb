{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "## Problem A _(25 points)_\n",
    "\n",
    "__A1.__ _(3 points)_ In this problem, you will be working with the [Seinfeld Chronicles dataset](https://www.kaggle.com/thec03u5/seinfeld-chronicles). Create an account on [Kaggle](https://www.kaggle.com) and download the `scripts.csv` file from the dataset and move it into the `data` directory. Read the `data/scripts.csv` file as a text file line-by-line and examine the list you have loaded the data into. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0   Character  \\\n",
      "0               0       JERRY   \n",
      "1               1       JERRY   \n",
      "2               2      GEORGE   \n",
      "3               3       JERRY   \n",
      "4               4      GEORGE   \n",
      "5               5       JERRY   \n",
      "6               6      GEORGE   \n",
      "7               7       JERRY   \n",
      "8               8      CLAIRE   \n",
      "9               9      GEORGE   \n",
      "10             10      CLAIRE   \n",
      "11             11       JERRY   \n",
      "12             12      CLAIRE   \n",
      "13             13      GEORGE   \n",
      "14             14       JERRY   \n",
      "15             15      GEORGE   \n",
      "16             16       JERRY   \n",
      "17             17      GEORGE   \n",
      "18             18       JERRY   \n",
      "19             19      GEORGE   \n",
      "20             20       JERRY   \n",
      "21             21      GEORGE   \n",
      "22             22       JERRY   \n",
      "23             23      GEORGE   \n",
      "24             24       JERRY   \n",
      "25             25      GEORGE   \n",
      "26             26       JERRY   \n",
      "27             27      GEORGE   \n",
      "28             28       JERRY   \n",
      "29             29      GEORGE   \n",
      "...           ...         ...   \n",
      "54586       54586       FRANK   \n",
      "54587       54587       SIDRA   \n",
      "54588       54588       JERRY   \n",
      "54589       54589      CHILES   \n",
      "54590       54590       JERRY   \n",
      "54591       54591      KRAMER   \n",
      "54592       54592      ELAINE   \n",
      "54593       54593      ELAINE   \n",
      "54594       54594       JERRY   \n",
      "54595       54595      ELAINE   \n",
      "54596       54596       JERRY   \n",
      "54597       54597      KRAMER   \n",
      "54598       54598       JERRY   \n",
      "54599       54599      GEORGE   \n",
      "54600       54600       JERRY   \n",
      "54601       54601      GEORGE   \n",
      "54602       54602       JERRY   \n",
      "54603       54603      GEORGE   \n",
      "54604       54604       JERRY   \n",
      "54605       54605       JERRY   \n",
      "54606       54606  PRISONER 1   \n",
      "54607       54607       JERRY   \n",
      "54608       54608  PRISONER 2   \n",
      "54609       54609       JERRY   \n",
      "54610       54610  PRISONER 3   \n",
      "54611       54611       JERRY   \n",
      "54612       54612  PRISONER 3   \n",
      "54613       54613       JERRY   \n",
      "54614       54614       GUARD   \n",
      "54615       54615       JERRY   \n",
      "\n",
      "                                                Dialogue  EpisodeNo    SEID  \\\n",
      "0      Do you know what this is all about? Do you kno...        1.0  S01E01   \n",
      "1      (pointing at Georges shirt) See, to me, that b...        1.0  S01E01   \n",
      "2                                       Are you through?        1.0  S01E01   \n",
      "3                 You do of course try on, when you buy?        1.0  S01E01   \n",
      "4      Yes, it was purple, I liked it, I dont actuall...        1.0  S01E01   \n",
      "5                                   Oh, you dont recall?        1.0  S01E01   \n",
      "6      (on an imaginary microphone) Uh, no, not at th...        1.0  S01E01   \n",
      "7      Well, senator, Id just like to know, what you ...        1.0  S01E01   \n",
      "8                            Mr. Seinfeld. Mr. Costanza.        1.0  S01E01   \n",
      "9      Are, are you sure this is decaf? Wheres the or...        1.0  S01E01   \n",
      "10     Its missing, I have to do it in my head decaf ...        1.0  S01E01   \n",
      "11     Can you relax, its a cup of coffee. Claire is ...        1.0  S01E01   \n",
      "12     Trust me George. No one has any interest in se...        1.0  S01E01   \n",
      "13     How come youre not doin the second show tomorrow?        1.0  S01E01   \n",
      "14        Well, theres this uh, woman might be comin in.        1.0  S01E01   \n",
      "15     Wait a second, wait a second, what coming in, ...        1.0  S01E01   \n",
      "16     I told you about Laura, the girl I met in Mich...        1.0  S01E01   \n",
      "17                                        No, you didnt!        1.0  S01E01   \n",
      "18     I thought I told you about it, yes, she teache...        1.0  S01E01   \n",
      "19                                                   Ha.        1.0  S01E01   \n",
      "20     (looks in the creamer) Theres no milk in here,...        1.0  S01E01   \n",
      "21     Wait wait wait, what is she... (takes the milk...        1.0  S01E01   \n",
      "22     Oh, shes really great. I mean, shes got like a...        1.0  S01E01   \n",
      "23          (smiling) So, you know, what, what happened?        1.0  S01E01   \n",
      "24     Oh, nothing happened, you know, but is was great.        1.0  S01E01   \n",
      "25                   Oh, nothing happened, but it was...        1.0  S01E01   \n",
      "26                                                 Yeah.        1.0  S01E01   \n",
      "27                                        This is great!        1.0  S01E01   \n",
      "28                                                 Yeah.        1.0  S01E01   \n",
      "29     So, you know, she calls and says she wants to ...        1.0  S01E01   \n",
      "...                                                  ...        ...     ...   \n",
      "54586  We gotta get out of here. We want to beat the ...       23.0  S09E23   \n",
      "54587                         Come on, Jackie. Let's go.       23.0  S09E23   \n",
      "54588                                              What?       23.0  S09E23   \n",
      "54589  Oh, and by the way, they're real, and they're ...       23.0  S09E23   \n",
      "54590  Well, it's only a year. That's not so bad. We'...       23.0  S09E23   \n",
      "54591  Could be fun. Don't have to worry about your m...       23.0  S09E23   \n",
      "54592           Why don't you just blow it out your a...       23.0  S09E23   \n",
      "54593  If I call Jill from prison, do you think that ...       23.0  S09E23   \n",
      "54594                                              Sure.       23.0  S09E23   \n",
      "54595  Cause you only get one call. The prison call i...       23.0  S09E23   \n",
      "54596         I think that would be a very nice gesture.       23.0  S09E23   \n",
      "54597  I got it - it's out! How about that, huh? Oh, ...       23.0  S09E23   \n",
      "54598  See now, to me, that button is in the worst po...       23.0  S09E23   \n",
      "54599                                            Really?       23.0  S09E23   \n",
      "54600  Oh yeah. The second button is the key button. ...       23.0  S09E23   \n",
      "54601           Haven't we had this conversation before?       23.0  S09E23   \n",
      "54602                                         You think?       23.0  S09E23   \n",
      "54603                                   I think we have.       23.0  S09E23   \n",
      "54604                               Yeah, maybe we have.       23.0  S09E23   \n",
      "54605  So what is the deal with the yard? I mean when...       23.0  S09E23   \n",
      "54606                                              I am.       23.0  S09E23   \n",
      "54607  I'll talk slower. I'm kidding - I love Cellblo...       23.0  S09E23   \n",
      "54608                                        Murder one.       23.0  S09E23   \n",
      "54609  Murder one? Oooooo, watch out everybody. Bette...       23.0  S09E23   \n",
      "54610                                  Grand theft auto.       23.0  S09E23   \n",
      "54611    Grand theft auto - don't steal any of my jokes.       23.0  S09E23   \n",
      "54612                      You suck - I'm gonna cut you.       23.0  S09E23   \n",
      "54613  Hey, I don't come down to where you work, and ...       23.0  S09E23   \n",
      "54614   Alright, Seinfeld, that's it. Let's go. Come on.       23.0  S09E23   \n",
      "54615  Alright, hey, you've been great! See you in th...       23.0  S09E23   \n",
      "\n",
      "       Season  \n",
      "0         1.0  \n",
      "1         1.0  \n",
      "2         1.0  \n",
      "3         1.0  \n",
      "4         1.0  \n",
      "5         1.0  \n",
      "6         1.0  \n",
      "7         1.0  \n",
      "8         1.0  \n",
      "9         1.0  \n",
      "10        1.0  \n",
      "11        1.0  \n",
      "12        1.0  \n",
      "13        1.0  \n",
      "14        1.0  \n",
      "15        1.0  \n",
      "16        1.0  \n",
      "17        1.0  \n",
      "18        1.0  \n",
      "19        1.0  \n",
      "20        1.0  \n",
      "21        1.0  \n",
      "22        1.0  \n",
      "23        1.0  \n",
      "24        1.0  \n",
      "25        1.0  \n",
      "26        1.0  \n",
      "27        1.0  \n",
      "28        1.0  \n",
      "29        1.0  \n",
      "...       ...  \n",
      "54586     9.0  \n",
      "54587     9.0  \n",
      "54588     9.0  \n",
      "54589     9.0  \n",
      "54590     9.0  \n",
      "54591     9.0  \n",
      "54592     9.0  \n",
      "54593     9.0  \n",
      "54594     9.0  \n",
      "54595     9.0  \n",
      "54596     9.0  \n",
      "54597     9.0  \n",
      "54598     9.0  \n",
      "54599     9.0  \n",
      "54600     9.0  \n",
      "54601     9.0  \n",
      "54602     9.0  \n",
      "54603     9.0  \n",
      "54604     9.0  \n",
      "54605     9.0  \n",
      "54606     9.0  \n",
      "54607     9.0  \n",
      "54608     9.0  \n",
      "54609     9.0  \n",
      "54610     9.0  \n",
      "54611     9.0  \n",
      "54612     9.0  \n",
      "54613     9.0  \n",
      "54614     9.0  \n",
      "54615     9.0  \n",
      "\n",
      "[54616 rows x 6 columns]\n",
      "This list includes the characters their dialogue throughout each episode of the Seinfeld series\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/scripts.csv')\n",
    "print(df)\n",
    "print(\"This list includes the characters their dialogue throughout each episode of the Seinfeld series\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A2.__ _(2 points)_ Is it possible to work with this data, simply splitting by a delimiter? Explain any complexity in the data's structured format that necessitates an established format-specific file reader. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: No, there's commas in the free text entries of the dialogue column! We'll mess up the column delimitation if we don't use a specialized tabular-data reader, like `csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A3.__ _(5 points)_ Use the `csv` module to read the contents of the `data/scripts.csv` file into a list. Examine this list. How many unique speaking characters are present in the scripts in total? \n",
    "\n",
    "__Important__: please don't get stuck on cleaning text in this problem! It's great to take note of issues in data and even address them, but the regular expressions (regex) required to get heavily into that work is ahead in __Chapter 4__ and so not required here. Please just count characters and words as best possible using the topics from Chapters 0&ndash;2 (naïvely, even), and utilize the markdown response boxes to discuss what you see as being the challenges in working with these data and what solutions might be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 Character                                           Dialogue  \\\n",
      "0           0     JERRY  Do you know what this is all about? Do you kno...   \n",
      "1           1     JERRY  (pointing at Georges shirt) See, to me, that b...   \n",
      "2           2    GEORGE                                   Are you through?   \n",
      "3           3     JERRY             You do of course try on, when you buy?   \n",
      "4           4    GEORGE  Yes, it was purple, I liked it, I dont actuall...   \n",
      "\n",
      "   EpisodeNo    SEID  Season  \n",
      "0        1.0  S01E01     1.0  \n",
      "1        1.0  S01E01     1.0  \n",
      "2        1.0  S01E01     1.0  \n",
      "3        1.0  S01E01     1.0  \n",
      "4        1.0  S01E01     1.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/scripts.csv')\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JERRY' 'GEORGE' 'CLAIRE' ... 'PRISONER 1' 'PRISONER 2' 'PRISONER 3']\n",
      "The number of unique speaking characters that are present in the scripts is as follows:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1639"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df[\"Character\"].unique())\n",
    "print(\"The number of unique speaking characters that are present in the scripts is as follows:\")\n",
    "len(df[\"Character\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A4.__ _(2 points)_ Count the dialogue entries for the four major characters, \"JERRY\", \"GEORGE\", \"ELAINE\", and \"KRAMER\", using a dictionary (you are not allowed to use the Counter data structure for any component of this problem).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Character', 'Dialogue', 'EpisodeNo', 'SEID', 'Season'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df[['Character', 'Dialogue']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The combined number of dialogue entries for the four major characters: JERRY, GEORGE, ELAINE, and KRAMER, is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39141"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.loc\n",
    "print(\"The combined number of dialogue entries for the four major characters: JERRY, GEORGE, ELAINE, and KRAMER, is\")\n",
    "len(df.loc[df['Character'] == \"JERRY\"]) + len(df.loc[df['Character'] == \"GEORGE\"]) + len(df.loc[df['Character'] == \"ELAINE\"]) + len(df.loc[df['Character'] == \"KRAMER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRUE ANSWER \n",
    "import csv\n",
    "\n",
    "reader = csv.reader(open(\"data/scripts.csv\", \"r\"))\n",
    "seinfeld = list(reader)\n",
    "\n",
    "counts = {\n",
    "    \"JERRY\" : 0,\n",
    "    \"GEORGE\" : 0,\n",
    "    \"ELAINE\" : 0,\n",
    "    \"KRAMER\" : 0\n",
    "}\n",
    "\n",
    "for lines in seinfeld:\n",
    "    if lines[1] in counts:\n",
    "        counts[lines[1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ELAINE': 7983, 'GEORGE': 9708, 'JERRY': 14786, 'KRAMER': 6664}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A5.__ _(3 points)_ Count the number of words spoken by each of the main characters using a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words spoken:\n",
      "Jerry: 49425\n",
      "George: 48792\n",
      "Elaine: 49235\n",
      "Kramer: 49093\n"
     ]
    }
   ],
   "source": [
    "#dict_characters= { \"JERRY\" : 0,    \"GEORGE\" : 0,    \"ELAINE\" : 0,    \"KRAMER\" : 0}\n",
    "#df[['Character' == \"JERRY\"], 'Dialogue']\n",
    "print(\"The number of words spoken:\")\n",
    "print(\"Jerry: \" + str(df.groupby([df['Character'] == \"JERRY\", \"Dialogue\"]).ngroups)) \n",
    "print(\"George: \" + str(df.groupby([df['Character'] == \"George\", \"Dialogue\"]).ngroups))\n",
    "print(\"Elaine: \" + str(df.groupby([df['Character'] == \"ELAINE\", \"Dialogue\"]).ngroups)) \n",
    "print(\"Kramer: \" + str(df.groupby([df['Character'] == \"KRAMER\", \"Dialogue\"]).ngroups)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corrected\n",
    "words_spoken = {\n",
    "    \"JERRY\" : 0,\n",
    "    \"GEORGE\" : 0,\n",
    "    \"ELAINE\" : 0,\n",
    "    \"KRAMER\" : 0\n",
    "}\n",
    "\n",
    "for lines in seinfeld:\n",
    "    if lines[1] in words_spoken:\n",
    "        num_words = len(lines[2].split())\n",
    "        words_spoken[lines[1]] += num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ELAINE': 74634, 'GEORGE': 107029, 'JERRY': 147389, 'KRAMER': 70299}\n"
     ]
    }
   ],
   "source": [
    "pprint(words_spoken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A6.__ _(5 points)_ Count how many times each word is spoken by the main characters using a dictionary, then sort these word counts in descending order, i.e. from the most commonly spoken words to least. [__Hint__: You can use either a lambda function or a list comprehension to do this.] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'apple': 3, 'egg': 2, 'banana': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#words = df['Dialogue']\n",
    "list1=['apple','egg','apple','banana','egg','apple']\n",
    "counts = Counter(list1)\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corrected\n",
    "word_counts = {\n",
    "    \"JERRY\" : {},\n",
    "    \"GEORGE\" : {},\n",
    "    \"ELAINE\" : {},\n",
    "    \"KRAMER\" : {}\n",
    "}\n",
    "\n",
    "for lines in seinfeld:\n",
    "    if lines[1] in word_counts:\n",
    "        words = [word.lower() for word in lines[2].split()]\n",
    "        for word in words:\n",
    "            if word in word_counts[lines[1]]:\n",
    "                word_counts[lines[1]][word] += 1\n",
    "            else:\n",
    "                word_counts[lines[1]][word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_word_counts = {\n",
    "    \"JERRY\" : {},\n",
    "    \"GEORGE\" : {},\n",
    "    \"ELAINE\" : {},\n",
    "    \"KRAMER\" : {}\n",
    "}\n",
    "\n",
    "for character in sorted_word_counts:\n",
    "    sorted_word_counts[character] = sorted(word_counts[character].items(), key = lambda x: x[1], reverse = True)\n",
    "#     this works, too\n",
    "#     sorted_word_counts[character] = sorted(((value, key) for (key, value) in word_counts[character].items()), reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A7.__ _(5 points)_ Load the `data/stop-words.txt` file into a list. Find the 10 most common words for each of the main characters that are not in this list of stop words. Put these most common words in a dictionary data strucutre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              a\n",
      "0         about\n",
      "1         above\n",
      "2         after\n",
      "3         again\n",
      "4       against\n",
      "5           ain\n",
      "6           all\n",
      "7            am\n",
      "8            an\n",
      "9           and\n",
      "10          any\n",
      "11          are\n",
      "12         aren\n",
      "13       aren't\n",
      "14           as\n",
      "15           at\n",
      "16           be\n",
      "17      because\n",
      "18         been\n",
      "19       before\n",
      "20        being\n",
      "21        below\n",
      "22      between\n",
      "23         both\n",
      "24          but\n",
      "25           by\n",
      "26          can\n",
      "27       couldn\n",
      "28     couldn't\n",
      "29            d\n",
      "..          ...\n",
      "148        wasn\n",
      "149      wasn't\n",
      "150          we\n",
      "151        were\n",
      "152       weren\n",
      "153     weren't\n",
      "154        what\n",
      "155        when\n",
      "156       where\n",
      "157       which\n",
      "158       while\n",
      "159         who\n",
      "160        whom\n",
      "161         why\n",
      "162        will\n",
      "163        with\n",
      "164         won\n",
      "165       won't\n",
      "166      wouldn\n",
      "167    wouldn't\n",
      "168           y\n",
      "169         you\n",
      "170       you'd\n",
      "171      you'll\n",
      "172      you're\n",
      "173      you've\n",
      "174        your\n",
      "175       yours\n",
      "176    yourself\n",
      "177  yourselves\n",
      "\n",
      "[178 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('data/stop-words.txt')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Unnamed:', 1), ('0', 1), ('Character', 1), ('Dialogue', 1), ('EpisodeNo', 1), ('SEID', 1), ('Season', 1)]\n"
     ]
    }
   ],
   "source": [
    "M = Counter(\" \".join(df).split()).most_common(10)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [word.strip() for word in open(\"data/stop-words.txt\", \"r\").readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_words = {\n",
    "    \"JERRY\" : [],\n",
    "    \"GEORGE\" : [],\n",
    "    \"ELAINE\" : [],\n",
    "    \"KRAMER\" : []\n",
    "}\n",
    "\n",
    "for character in most_common_words:\n",
    "    count = 0\n",
    "    for word in sorted_word_counts[character]:\n",
    "        if count == 10:\n",
    "            break\n",
    "        if not word[0] in stop_words:\n",
    "            most_common_words[character].append(word)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ELAINE': [('oh,', 506),\n",
      "            (\"i'm\", 495),\n",
      "            ('well,', 353),\n",
      "            ('know', 330),\n",
      "            ('get', 309),\n",
      "            ('yeah,', 307),\n",
      "            ('no,', 307),\n",
      "            ('like', 298),\n",
      "            ('got', 267),\n",
      "            ('what?', 258)],\n",
      " 'GEORGE': [(\"i'm\", 826),\n",
      "            ('like', 583),\n",
      "            ('get', 492),\n",
      "            ('know', 483),\n",
      "            ('think', 379),\n",
      "            ('got', 375),\n",
      "            ('well,', 370),\n",
      "            (\"that's\", 366),\n",
      "            ('oh,', 353),\n",
      "            ('it.', 328)],\n",
      " 'JERRY': [(\"i'm\", 888),\n",
      "           ('like', 783),\n",
      "           ('get', 736),\n",
      "           ('know', 697),\n",
      "           ('well,', 607),\n",
      "           ('oh,', 595),\n",
      "           (\"that's\", 544),\n",
      "           ('it.', 521),\n",
      "           ('got', 512),\n",
      "           ('yeah,', 510)],\n",
      " 'KRAMER': [('well,', 576),\n",
      "            (\"i'm\", 554),\n",
      "            ('yeah,', 515),\n",
      "            ('oh,', 403),\n",
      "            ('got', 395),\n",
      "            ('get', 330),\n",
      "            ('no,', 298),\n",
      "            ('yeah.', 298),\n",
      "            ('like', 294),\n",
      "            ('know', 291)]}\n"
     ]
    }
   ],
   "source": [
    "pprint(most_common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem B _(25 points)_\n",
    "\n",
    "__B1.__ _(5 points)_ You will be using part of the [Goodbooks 10k dataset](https://github.com/zygmuntz/goodbooks-10k) for this problem. Read the `data/goodreads-books.csv` file into a list. Create a dictionary for each book in the list that contains these fields: authors, original title, original publication year, average rating, and ratings count. (You should convert average rating and ratings count into `float` and `int` types.) Put all these metadata dictionaries into a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      book_id  goodreads_book_id  best_book_id   work_id  books_count  \\\n",
      "0           1            2767052       2767052   2792775          272   \n",
      "1           2                  3             3   4640799          491   \n",
      "2           3              41865         41865   3212258          226   \n",
      "3           4               2657          2657   3275794          487   \n",
      "4           5               4671          4671    245494         1356   \n",
      "5           6           11870085      11870085  16827462          226   \n",
      "6           7               5907          5907   1540236          969   \n",
      "7           8               5107          5107   3036731          360   \n",
      "8           9                960           960   3338963          311   \n",
      "9          10               1885          1885   3060926         3455   \n",
      "10         11              77203         77203   3295919          283   \n",
      "11         12           13335037      13335037  13155899          210   \n",
      "12         13               5470          5470    153313          995   \n",
      "13         14               7613          7613   2207778          896   \n",
      "14         15              48855         48855   3532896          710   \n",
      "15         16            2429135       2429135   1708725          274   \n",
      "16         17            6148028       6148028   6171458          201   \n",
      "17         18                  5             5   2402163          376   \n",
      "18         19                 34            34   3204327          566   \n",
      "19         20            7260188       7260188   8812783          239   \n",
      "20         21                  2             2   2809203          307   \n",
      "21         22           12232938      12232938   1145090          183   \n",
      "22         23              15881         15881   6231171          398   \n",
      "23         24                  6             6   3046572          332   \n",
      "24         25             136251        136251   2963218          263   \n",
      "25         26                968           968   2982101          350   \n",
      "26         27                  1             1  41335427          275   \n",
      "27         28               7624          7624   2766512          458   \n",
      "28         29              18135         18135   3349450         1937   \n",
      "29         30            8442457      19288043  13306276          196   \n",
      "...       ...                ...           ...       ...          ...   \n",
      "9970     9971           12602078      25781538  17617275            8   \n",
      "9971     9972               4984          4984   6558445           28   \n",
      "9972     9973             849380        849380      4370           52   \n",
      "9973     9974             116494        116494    827585           38   \n",
      "9974     9975             613991        613991    835285           40   \n",
      "9975     9976            6351939       6351939   6538518           24   \n",
      "9976     9977             202948        202948    851165           55   \n",
      "9977     9978             162332        162332    880874           70   \n",
      "9978     9979              16951         16951    891697           57   \n",
      "9979     9980             946899        946899     88345           11   \n",
      "9980     9981             106312        106312     29083           58   \n",
      "9981     9982           12444298      12444298  21900571            1   \n",
      "9982     9983            8539798       8539798   8097499           16   \n",
      "9983     9984             764165        764165   1824318           39   \n",
      "9984     9985              19688         19688  17028947           24   \n",
      "9985     9986             183092        183092    176939           16   \n",
      "9986     9987            8087038       8087038  12823536           29   \n",
      "9987     9988             129237        129237   1383130           44   \n",
      "9988     9989           13489518      13489518  19028216            9   \n",
      "9989     9990             294081        294081     14081           40   \n",
      "9990     9991             101094        101094   1198275           37   \n",
      "9991     9992           13616278      13616278  19217996           26   \n",
      "9992     9993            4936457       4936457   5002120           27   \n",
      "9993     9994            4769651       4769651   4834466            2   \n",
      "9994     9995              15613         15613   2764239          199   \n",
      "9995     9996            7130616       7130616   7392860           19   \n",
      "9996     9997             208324        208324   1084709           19   \n",
      "9997     9998              77431         77431   2393986           60   \n",
      "9998     9999            8565083       8565083  13433613            7   \n",
      "9999    10000               8914          8914     11817           31   \n",
      "\n",
      "            isbn        isbn13  \\\n",
      "0      439023483  9.780439e+12   \n",
      "1      439554934  9.780440e+12   \n",
      "2      316015849  9.780316e+12   \n",
      "3       61120081  9.780061e+12   \n",
      "4      743273567  9.780743e+12   \n",
      "5      525478817  9.780525e+12   \n",
      "6      618260307  9.780618e+12   \n",
      "7      316769177  9.780317e+12   \n",
      "8     1416524797  9.781417e+12   \n",
      "9      679783261  9.780680e+12   \n",
      "10    1594480001  9.781594e+12   \n",
      "11      62024035  9.780062e+12   \n",
      "12     451524934  9.780452e+12   \n",
      "13     452284244  9.780452e+12   \n",
      "14     553296981  9.780553e+12   \n",
      "15     307269752  9.780307e+12   \n",
      "16     439023491  9.780439e+12   \n",
      "17    043965548X  9.780440e+12   \n",
      "18     618346252  9.780618e+12   \n",
      "19     439023513  9.780439e+12   \n",
      "20     439358078  9.780439e+12   \n",
      "21     316166685  9.780316e+12   \n",
      "22     439064864  9.780439e+12   \n",
      "23     439139600  9.780439e+12   \n",
      "24     545010225  9.780545e+12   \n",
      "25     307277674  9.780307e+12   \n",
      "26     439785960  9.780440e+12   \n",
      "27     140283331  9.780140e+12   \n",
      "28     743477111  9.780743e+12   \n",
      "29     297859382  9.780298e+12   \n",
      "...          ...           ...   \n",
      "9970         NaN           NaN   \n",
      "9971    99282968  9.780099e+12   \n",
      "9972   609805797  9.780610e+12   \n",
      "9973   553153382  9.780553e+12   \n",
      "9974  1857236653  9.781857e+12   \n",
      "9975   778325806  9.780778e+12   \n",
      "9976   804113475  9.780804e+12   \n",
      "9977   679750150  9.780680e+12   \n",
      "9978   312940661  9.780313e+12   \n",
      "9979   764200739  9.780764e+12   \n",
      "9980   739455834  9.780739e+12   \n",
      "9981   385344422  9.780385e+12   \n",
      "9982  2849659266  9.782850e+12   \n",
      "9983   140255087  9.780140e+12   \n",
      "9984   425176932  9.780425e+12   \n",
      "9985   310257689  9.780310e+12   \n",
      "9986   312651198  9.780313e+12   \n",
      "9987   674017722  9.780674e+12   \n",
      "9988         NaN  2.940015e+12   \n",
      "9989   140143912  9.780140e+12   \n",
      "9990   385425139  9.780385e+12   \n",
      "9991   575113294  9.780575e+12   \n",
      "9992   224079948  9.780224e+12   \n",
      "9993   810983559  9.780811e+12   \n",
      "9994  1416523723  9.781417e+12   \n",
      "9995   441019455  9.780441e+12   \n",
      "9996  067973371X  9.780680e+12   \n",
      "9997  039330762X  9.780393e+12   \n",
      "9998    61711527  9.780062e+12   \n",
      "9999   375700455  9.780376e+12   \n",
      "\n",
      "                                                authors  \\\n",
      "0                                       Suzanne Collins   \n",
      "1                           J.K. Rowling, Mary GrandPré   \n",
      "2                                       Stephenie Meyer   \n",
      "3                                            Harper Lee   \n",
      "4                                   F. Scott Fitzgerald   \n",
      "5                                            John Green   \n",
      "6                                        J.R.R. Tolkien   \n",
      "7                                         J.D. Salinger   \n",
      "8                                             Dan Brown   \n",
      "9                                           Jane Austen   \n",
      "10                                      Khaled Hosseini   \n",
      "11                                        Veronica Roth   \n",
      "12              George Orwell, Erich Fromm, Celâl Üster   \n",
      "13                                        George Orwell   \n",
      "14    Anne Frank, Eleanor Roosevelt, B.M. Mooyaart-D...   \n",
      "15                           Stieg Larsson, Reg Keeland   \n",
      "16                                      Suzanne Collins   \n",
      "17              J.K. Rowling, Mary GrandPré, Rufus Beck   \n",
      "18                                       J.R.R. Tolkien   \n",
      "19                                      Suzanne Collins   \n",
      "20                          J.K. Rowling, Mary GrandPré   \n",
      "21                                         Alice Sebold   \n",
      "22                          J.K. Rowling, Mary GrandPré   \n",
      "23                          J.K. Rowling, Mary GrandPré   \n",
      "24                          J.K. Rowling, Mary GrandPré   \n",
      "25                                            Dan Brown   \n",
      "26                          J.K. Rowling, Mary GrandPré   \n",
      "27                                      William Golding   \n",
      "28        William Shakespeare, Robert           Jackson   \n",
      "29                                        Gillian Flynn   \n",
      "...                                                 ...   \n",
      "9970                                        Melody Anne   \n",
      "9971                                  Kurt Vonnegut Jr.   \n",
      "9972                        John M. Gottman, Nan Silver   \n",
      "9973                                         Lois Lowry   \n",
      "9974                                      David Gemmell   \n",
      "9975                                    Maria V. Snyder   \n",
      "9976                                         Anne Tyler   \n",
      "9977                         Yukio Mishima, John Nathan   \n",
      "9978                                       Wilbur Smith   \n",
      "9979                                       Deeanne Gist   \n",
      "9980                                     Jeffery Deaver   \n",
      "9981                                 Karen Marie Moning   \n",
      "9982                                         Kazue Kato   \n",
      "9983                                  Peter Matthiessen   \n",
      "9984           Steve Perry, Tom Clancy, Steve Pieczenik   \n",
      "9985                                   Terri Blackstock   \n",
      "9986                                      Iris Johansen   \n",
      "9987                                         John Rawls   \n",
      "9988                                       Quinn Loftis   \n",
      "9989                                     Oscar Hijuelos   \n",
      "9990                                           Ben Okri   \n",
      "9991                                     Miles  Cameron   \n",
      "9992                                       Ian Mortimer   \n",
      "9993                    Michael Buckley, Peter Ferguson   \n",
      "9994                                    Herman Melville   \n",
      "9995                                      Ilona Andrews   \n",
      "9996                                     Robert A. Caro   \n",
      "9997                                    Patrick O'Brian   \n",
      "9998                                    Peggy Orenstein   \n",
      "9999                                        John Keegan   \n",
      "\n",
      "      original_publication_year  \\\n",
      "0                        2008.0   \n",
      "1                        1997.0   \n",
      "2                        2005.0   \n",
      "3                        1960.0   \n",
      "4                        1925.0   \n",
      "5                        2012.0   \n",
      "6                        1937.0   \n",
      "7                        1951.0   \n",
      "8                        2000.0   \n",
      "9                        1813.0   \n",
      "10                       2003.0   \n",
      "11                       2011.0   \n",
      "12                       1949.0   \n",
      "13                       1945.0   \n",
      "14                       1947.0   \n",
      "15                       2005.0   \n",
      "16                       2009.0   \n",
      "17                       1999.0   \n",
      "18                       1954.0   \n",
      "19                       2010.0   \n",
      "20                       2003.0   \n",
      "21                       2002.0   \n",
      "22                       1998.0   \n",
      "23                       2000.0   \n",
      "24                       2007.0   \n",
      "25                       2003.0   \n",
      "26                       2005.0   \n",
      "27                       1954.0   \n",
      "28                       1595.0   \n",
      "29                       2012.0   \n",
      "...                         ...   \n",
      "9970                     2011.0   \n",
      "9971                     1999.0   \n",
      "9972                     1999.0   \n",
      "9973                     1978.0   \n",
      "9974                     1985.0   \n",
      "9975                     2009.0   \n",
      "9976                     1995.0   \n",
      "9977                     1963.0   \n",
      "9978                     1964.0   \n",
      "9979                     2006.0   \n",
      "9980                     2005.0   \n",
      "9981                     2016.0   \n",
      "9982                     2009.0   \n",
      "9983                     1978.0   \n",
      "9984                     2000.0   \n",
      "9985                     2006.0   \n",
      "9986                     2010.0   \n",
      "9987                     1971.0   \n",
      "9988                     2012.0   \n",
      "9989                     1989.0   \n",
      "9990                     1991.0   \n",
      "9991                     2012.0   \n",
      "9992                     2008.0   \n",
      "9993                     2009.0   \n",
      "9994                     1924.0   \n",
      "9995                     2010.0   \n",
      "9996                     1990.0   \n",
      "9997                     1977.0   \n",
      "9998                     2011.0   \n",
      "9999                     1998.0   \n",
      "\n",
      "                                         original_title  \\\n",
      "0                                      The Hunger Games   \n",
      "1              Harry Potter and the Philosopher's Stone   \n",
      "2                                              Twilight   \n",
      "3                                 To Kill a Mockingbird   \n",
      "4                                      The Great Gatsby   \n",
      "5                                The Fault in Our Stars   \n",
      "6                    The Hobbit or There and Back Again   \n",
      "7                                The Catcher in the Rye   \n",
      "8                                      Angels & Demons    \n",
      "9                                   Pride and Prejudice   \n",
      "10                                     The Kite Runner    \n",
      "11                                            Divergent   \n",
      "12                                 Nineteen Eighty-Four   \n",
      "13                           Animal Farm: A Fairy Story   \n",
      "14    Het Achterhuis: Dagboekbrieven 14 juni 1942 - ...   \n",
      "15                                Män som hatar kvinnor   \n",
      "16                                        Catching Fire   \n",
      "17             Harry Potter and the Prisoner of Azkaban   \n",
      "18                           The Fellowship of the Ring   \n",
      "19                                           Mockingjay   \n",
      "20            Harry Potter and the Order of the Phoenix   \n",
      "21                                     The Lovely Bones   \n",
      "22              Harry Potter and the Chamber of Secrets   \n",
      "23                  Harry Potter and the Goblet of Fire   \n",
      "24                 Harry Potter and the Deathly Hallows   \n",
      "25                                    The Da Vinci Code   \n",
      "26               Harry Potter and the Half-Blood Prince   \n",
      "27                                   Lord of the Flies    \n",
      "28    An Excellent conceited Tragedie of Romeo and J...   \n",
      "29                                            Gone Girl   \n",
      "...                                                 ...   \n",
      "9970                                                NaN   \n",
      "9971                                  Bagombo Snuff Box   \n",
      "9972  The Seven Principles for Making Marriage Work:...   \n",
      "9973                                  Anastasia Krupnik   \n",
      "9974                           The King Beyond the Gate   \n",
      "9975                                          Sea Glass   \n",
      "9976                                    Ladder of Years   \n",
      "9977                               午後の曳航 [Gogo no eikō]   \n",
      "9978                                When the Lion Feeds   \n",
      "9979                              The Measure of a Lady   \n",
      "9980                                   The Twelfth Card   \n",
      "9981                                          Feverborn   \n",
      "9982                                            青の祓魔師 2   \n",
      "9983                                   The Snow Leopard   \n",
      "9984             Tom Clancy's Net Force: Breaking Point   \n",
      "9985                   Night Light: A Restoration Novel   \n",
      "9986                                  Chasing The Night   \n",
      "9987                                A Theory of Justice   \n",
      "9988                                   Out of the Dark    \n",
      "9989                 The Mambo Kings Play Songs of Love   \n",
      "9990                                  The Famished Road   \n",
      "9991                                     The Red Knight   \n",
      "9992  The Time-Traveller's Guide to Medieval England...   \n",
      "9993          The Everafter War (The Sisters Grimm, #7)   \n",
      "9994                                 Billy Budd, Sailor   \n",
      "9995                                         Bayou Moon   \n",
      "9996                                   Means of Ascent    \n",
      "9997                              The Mauritius Command   \n",
      "9998  Cinderella Ate My Daughter: Dispatches from th...   \n",
      "9999                                The First World War   \n",
      "\n",
      "                            ...                         ratings_count  \\\n",
      "0                           ...                               4780653   \n",
      "1                           ...                               4602479   \n",
      "2                           ...                               3866839   \n",
      "3                           ...                               3198671   \n",
      "4                           ...                               2683664   \n",
      "5                           ...                               2346404   \n",
      "6                           ...                               2071616   \n",
      "7                           ...                               2044241   \n",
      "8                           ...                               2001311   \n",
      "9                           ...                               2035490   \n",
      "10                          ...                               1813044   \n",
      "11                          ...                               1903563   \n",
      "12                          ...                               1956832   \n",
      "13                          ...                               1881700   \n",
      "14                          ...                               1972666   \n",
      "15                          ...                               1808403   \n",
      "16                          ...                               1831039   \n",
      "17                          ...                               1832823   \n",
      "18                          ...                               1766803   \n",
      "19                          ...                               1719760   \n",
      "20                          ...                               1735368   \n",
      "21                          ...                               1605173   \n",
      "22                          ...                               1779331   \n",
      "23                          ...                               1753043   \n",
      "24                          ...                               1746574   \n",
      "25                          ...                               1447148   \n",
      "26                          ...                               1678823   \n",
      "27                          ...                               1605019   \n",
      "28                          ...                               1628519   \n",
      "29                          ...                                512475   \n",
      "...                         ...                                   ...   \n",
      "9970                        ...                                 10989   \n",
      "9971                        ...                                  7407   \n",
      "9972                        ...                                  8868   \n",
      "9973                        ...                                 11914   \n",
      "9974                        ...                                  9305   \n",
      "9975                        ...                                 14440   \n",
      "9976                        ...                                 11209   \n",
      "9977                        ...                                  8810   \n",
      "9978                        ...                                  8440   \n",
      "9979                        ...                                  9583   \n",
      "9980                        ...                                 10188   \n",
      "9981                        ...                                 11570   \n",
      "9982                        ...                                  8972   \n",
      "9983                        ...                                  8502   \n",
      "9984                        ...                                  7693   \n",
      "9985                        ...                                  8471   \n",
      "9986                        ...                                 10129   \n",
      "9987                        ...                                  8472   \n",
      "9988                        ...                                 11994   \n",
      "9989                        ...                                  9107   \n",
      "9990                        ...                                  8251   \n",
      "9991                        ...                                  8556   \n",
      "9992                        ...                                  9824   \n",
      "9993                        ...                                 12493   \n",
      "9994                        ...                                 10866   \n",
      "9995                        ...                                 17204   \n",
      "9996                        ...                                 12582   \n",
      "9997                        ...                                  9421   \n",
      "9998                        ...                                 11279   \n",
      "9999                        ...                                  9162   \n",
      "\n",
      "     work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
      "0               4942365                   155254      66715     127936   \n",
      "1               4800065                    75867      75504     101676   \n",
      "2               3916824                    95009     456191     436802   \n",
      "3               3340896                    72586      60427     117415   \n",
      "4               2773745                    51992      86236     197621   \n",
      "5               2478609                   140739      47994      92723   \n",
      "6               2196809                    37653      46023      76784   \n",
      "7               2120637                    44920     109383     185520   \n",
      "8               2078754                    25112      77841     145740   \n",
      "9               2191465                    49152      54700      86485   \n",
      "10              1878095                    59730      34288      59980   \n",
      "11              2216814                   101023      36315      82870   \n",
      "12              2053394                    45518      41845      86425   \n",
      "13              1982987                    35472      66854     135147   \n",
      "14              2024493                    20825      45225      91270   \n",
      "15              1929834                    62543      54835      86051   \n",
      "16              1988079                    88538      10492      48030   \n",
      "17              1969375                    36099       6716      20413   \n",
      "18              1832541                    15333      38031      55862   \n",
      "19              1870748                    96274      30144     110498   \n",
      "20              1840548                    28685       9528      31577   \n",
      "21              1661562                    36642      62777     131188   \n",
      "22              1906199                    34172       8253      42251   \n",
      "23              1868642                    31084       6676      20210   \n",
      "24              1847395                    51942       9363      22245   \n",
      "25              1557292                    41560      71345     126493   \n",
      "26              1785676                    27520       7308      21516   \n",
      "27              1671484                    26886      92779     160295   \n",
      "28              1672889                    14778      57980     153179   \n",
      "29              1626519                   121614      38874      80807   \n",
      "...                 ...                      ...        ...        ...   \n",
      "9970              17606                      881        395       1182   \n",
      "9971               8597                      316         78        548   \n",
      "9972              10017                      749        126        334   \n",
      "9973              12519                      389        440        603   \n",
      "9974              10307                      149         49        249   \n",
      "9975              15937                      855        118        655   \n",
      "9976              12229                      949        214        854   \n",
      "9977              10541                      755        142        590   \n",
      "9978               9581                      322         64        268   \n",
      "9979               9963                      489        187        608   \n",
      "9980              12134                      495         72        390   \n",
      "9981              14194                     1891        179        521   \n",
      "9982               9859                      153         32        152   \n",
      "9983               9532                      686        145        406   \n",
      "9984               7825                       26        268        684   \n",
      "9985               8862                      218         96        172   \n",
      "9986              10964                      411        113        331   \n",
      "9987               9108                      168        234        607   \n",
      "9988              13614                      595         72        229   \n",
      "9989               9776                      421        374        836   \n",
      "9990               8875                      586        465        815   \n",
      "9991              10102                      742        232        491   \n",
      "9992              12115                      970        236        521   \n",
      "9993              12965                      455        110        289   \n",
      "9994              12110                      681       1478       2225   \n",
      "9995              18856                     1180        105        575   \n",
      "9996              12952                      395        303        551   \n",
      "9997              10733                      374         11        111   \n",
      "9998              11994                     1988        275       1002   \n",
      "9999               9700                      364        117        345   \n",
      "\n",
      "      ratings_3  ratings_4  ratings_5  \\\n",
      "0        560092    1481305    2706317   \n",
      "1        455024    1156318    3011543   \n",
      "2        793319     875073    1355439   \n",
      "3        446835    1001952    1714267   \n",
      "4        606158     936012     947718   \n",
      "5        327550     698471    1311871   \n",
      "6        288649     665635    1119718   \n",
      "7        455042     661516     709176   \n",
      "8        458429     716569     680175   \n",
      "9        284852     609755    1155673   \n",
      "10       226062     628174     929591   \n",
      "11       310297     673028    1114304   \n",
      "12       324874     692021     908229   \n",
      "13       433432     698642     648912   \n",
      "14       355756     656870     875372   \n",
      "15       285413     667485     836050   \n",
      "16       262010     687238     980309   \n",
      "17       166129     509447    1266670   \n",
      "18       202332     493922    1042394   \n",
      "19       373060     618271     738775   \n",
      "20       180210     494427    1124806   \n",
      "21       404699     583575     479323   \n",
      "22       242345     548266    1065084   \n",
      "23       151785     494926    1195045   \n",
      "24       113646     383914    1318227   \n",
      "25       340790     539277     479387   \n",
      "26       136333     459028    1161491   \n",
      "27       425648     564916     427846   \n",
      "28       452673     519822     489235   \n",
      "29       280331     616031     610476   \n",
      "...         ...        ...        ...   \n",
      "9970       4378       6060       5591   \n",
      "9971       2817       3430       1724   \n",
      "9972       1604       3446       4507   \n",
      "9973       3062       4185       4229   \n",
      "9974       1968       4174       3867   \n",
      "9975       3685       6185       5294   \n",
      "9976       3714       4827       2620   \n",
      "9977       2414       4551       2844   \n",
      "9978       1648       3732       3869   \n",
      "9979       2337       3355       3476   \n",
      "9980       2874       5155       3643   \n",
      "9981       2308       4779       6407   \n",
      "9982       1025       2479       6171   \n",
      "9983       1586       3393       4002   \n",
      "9984       2349       2456       2068   \n",
      "9985       1115       2658       4821   \n",
      "9986       2127       3957       4436   \n",
      "9987       2001       3171       3095   \n",
      "9988       1263       3280       8770   \n",
      "9989       2692       3513       2361   \n",
      "9990       2046       2895       2654   \n",
      "9991       1375       3712       4292   \n",
      "9992       2497       4790       4071   \n",
      "9993       1745       3989       6832   \n",
      "9994       3805       2985       1617   \n",
      "9995       3538       7860       6778   \n",
      "9996       1737       3389       6972   \n",
      "9997       1191       4240       5180   \n",
      "9998       3765       4577       2375   \n",
      "9999       2031       4138       3069   \n",
      "\n",
      "                                              image_url  \\\n",
      "0     https://images.gr-assets.com/books/1447303603m...   \n",
      "1     https://images.gr-assets.com/books/1474154022m...   \n",
      "2     https://images.gr-assets.com/books/1361039443m...   \n",
      "3     https://images.gr-assets.com/books/1361975680m...   \n",
      "4     https://images.gr-assets.com/books/1490528560m...   \n",
      "5     https://images.gr-assets.com/books/1360206420m...   \n",
      "6     https://images.gr-assets.com/books/1372847500m...   \n",
      "7     https://images.gr-assets.com/books/1398034300m...   \n",
      "8     https://images.gr-assets.com/books/1303390735m...   \n",
      "9     https://images.gr-assets.com/books/1320399351m...   \n",
      "10    https://images.gr-assets.com/books/1484565687m...   \n",
      "11    https://images.gr-assets.com/books/1328559506m...   \n",
      "12    https://images.gr-assets.com/books/1348990566m...   \n",
      "13    https://images.gr-assets.com/books/1424037542m...   \n",
      "14    https://images.gr-assets.com/books/1358276407m...   \n",
      "15    https://images.gr-assets.com/books/1327868566m...   \n",
      "16    https://images.gr-assets.com/books/1358273780m...   \n",
      "17    https://images.gr-assets.com/books/1499277281m...   \n",
      "18    https://images.gr-assets.com/books/1298411339m...   \n",
      "19    https://images.gr-assets.com/books/1358275419m...   \n",
      "20    https://images.gr-assets.com/books/1387141547m...   \n",
      "21    https://images.gr-assets.com/books/1457810586m...   \n",
      "22    https://images.gr-assets.com/books/1474169725m...   \n",
      "23    https://images.gr-assets.com/books/1361482611m...   \n",
      "24    https://images.gr-assets.com/books/1474171184m...   \n",
      "25    https://images.gr-assets.com/books/1303252999m...   \n",
      "26    https://images.gr-assets.com/books/1361039191m...   \n",
      "27    https://images.gr-assets.com/books/1327869409m...   \n",
      "28    https://images.gr-assets.com/books/1327872146m...   \n",
      "29    https://images.gr-assets.com/books/1339602131m...   \n",
      "...                                                 ...   \n",
      "9970  https://images.gr-assets.com/books/1368675679m...   \n",
      "9971  https://images.gr-assets.com/books/1327353727m...   \n",
      "9972  https://images.gr-assets.com/books/1320521960m...   \n",
      "9973  https://images.gr-assets.com/books/1476942137m...   \n",
      "9974  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
      "9975  https://images.gr-assets.com/books/1327132670m...   \n",
      "9976  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
      "9977  https://images.gr-assets.com/books/1327629352m...   \n",
      "9978  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
      "9979  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
      "9980  https://images.gr-assets.com/books/1328407138m...   \n",
      "9981  https://images.gr-assets.com/books/1435195536m...   \n",
      "9982  https://images.gr-assets.com/books/1278403940m...   \n",
      "9983  https://images.gr-assets.com/books/1309211772m...   \n",
      "9984  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
      "9985  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
      "9986  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
      "9987  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
      "9988  https://images.gr-assets.com/books/1334785691m...   \n",
      "9989  https://images.gr-assets.com/books/1330072994m...   \n",
      "9990  https://images.gr-assets.com/books/1344396715m...   \n",
      "9991  https://images.gr-assets.com/books/1348037761m...   \n",
      "9992  https://images.gr-assets.com/books/1328167619m...   \n",
      "9993  https://images.gr-assets.com/books/1388278230m...   \n",
      "9994  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
      "9995  https://images.gr-assets.com/books/1307445460m...   \n",
      "9996  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
      "9997  https://images.gr-assets.com/books/1455373531m...   \n",
      "9998  https://images.gr-assets.com/books/1279214118m...   \n",
      "9999  https://images.gr-assets.com/books/1403194704m...   \n",
      "\n",
      "                                        small_image_url  \n",
      "0     https://images.gr-assets.com/books/1447303603s...  \n",
      "1     https://images.gr-assets.com/books/1474154022s...  \n",
      "2     https://images.gr-assets.com/books/1361039443s...  \n",
      "3     https://images.gr-assets.com/books/1361975680s...  \n",
      "4     https://images.gr-assets.com/books/1490528560s...  \n",
      "5     https://images.gr-assets.com/books/1360206420s...  \n",
      "6     https://images.gr-assets.com/books/1372847500s...  \n",
      "7     https://images.gr-assets.com/books/1398034300s...  \n",
      "8     https://images.gr-assets.com/books/1303390735s...  \n",
      "9     https://images.gr-assets.com/books/1320399351s...  \n",
      "10    https://images.gr-assets.com/books/1484565687s...  \n",
      "11    https://images.gr-assets.com/books/1328559506s...  \n",
      "12    https://images.gr-assets.com/books/1348990566s...  \n",
      "13    https://images.gr-assets.com/books/1424037542s...  \n",
      "14    https://images.gr-assets.com/books/1358276407s...  \n",
      "15    https://images.gr-assets.com/books/1327868566s...  \n",
      "16    https://images.gr-assets.com/books/1358273780s...  \n",
      "17    https://images.gr-assets.com/books/1499277281s...  \n",
      "18    https://images.gr-assets.com/books/1298411339s...  \n",
      "19    https://images.gr-assets.com/books/1358275419s...  \n",
      "20    https://images.gr-assets.com/books/1387141547s...  \n",
      "21    https://images.gr-assets.com/books/1457810586s...  \n",
      "22    https://images.gr-assets.com/books/1474169725s...  \n",
      "23    https://images.gr-assets.com/books/1361482611s...  \n",
      "24    https://images.gr-assets.com/books/1474171184s...  \n",
      "25    https://images.gr-assets.com/books/1303252999s...  \n",
      "26    https://images.gr-assets.com/books/1361039191s...  \n",
      "27    https://images.gr-assets.com/books/1327869409s...  \n",
      "28    https://images.gr-assets.com/books/1327872146s...  \n",
      "29    https://images.gr-assets.com/books/1339602131s...  \n",
      "...                                                 ...  \n",
      "9970  https://images.gr-assets.com/books/1368675679s...  \n",
      "9971  https://images.gr-assets.com/books/1327353727s...  \n",
      "9972  https://images.gr-assets.com/books/1320521960s...  \n",
      "9973  https://images.gr-assets.com/books/1476942137s...  \n",
      "9974  https://s.gr-assets.com/assets/nophoto/book/50...  \n",
      "9975  https://images.gr-assets.com/books/1327132670s...  \n",
      "9976  https://s.gr-assets.com/assets/nophoto/book/50...  \n",
      "9977  https://images.gr-assets.com/books/1327629352s...  \n",
      "9978  https://s.gr-assets.com/assets/nophoto/book/50...  \n",
      "9979  https://s.gr-assets.com/assets/nophoto/book/50...  \n",
      "9980  https://images.gr-assets.com/books/1328407138s...  \n",
      "9981  https://images.gr-assets.com/books/1435195536s...  \n",
      "9982  https://images.gr-assets.com/books/1278403940s...  \n",
      "9983  https://images.gr-assets.com/books/1309211772s...  \n",
      "9984  https://s.gr-assets.com/assets/nophoto/book/50...  \n",
      "9985  https://s.gr-assets.com/assets/nophoto/book/50...  \n",
      "9986  https://s.gr-assets.com/assets/nophoto/book/50...  \n",
      "9987  https://s.gr-assets.com/assets/nophoto/book/50...  \n",
      "9988  https://images.gr-assets.com/books/1334785691s...  \n",
      "9989  https://images.gr-assets.com/books/1330072994s...  \n",
      "9990  https://images.gr-assets.com/books/1344396715s...  \n",
      "9991  https://images.gr-assets.com/books/1348037761s...  \n",
      "9992  https://images.gr-assets.com/books/1328167619s...  \n",
      "9993  https://images.gr-assets.com/books/1388278230s...  \n",
      "9994  https://s.gr-assets.com/assets/nophoto/book/50...  \n",
      "9995  https://images.gr-assets.com/books/1307445460s...  \n",
      "9996  https://s.gr-assets.com/assets/nophoto/book/50...  \n",
      "9997  https://images.gr-assets.com/books/1455373531s...  \n",
      "9998  https://images.gr-assets.com/books/1279214118s...  \n",
      "9999  https://images.gr-assets.com/books/1403194704s...  \n",
      "\n",
      "[10000 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df5 = pd.read_csv('data/goodreads-books.csv')\n",
    "print(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "Booksline = csv.reader(open(\"data/goodreads-books.csv\", \"r\"))\n",
    "Books = {}\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'original_title': 'The Hunger Games', 'authors': 'Suzanne Collins', 'original_publication_year': '2008.0', 'ratings_count': 4780653, 'average_rating': 4.34}, {'original_title': \"Harry Potter and the Philosopher's Stone\", 'authors': 'J.K. Rowling, Mary GrandPrÃ©', 'original_publication_year': '1997.0', 'ratings_count': 4602479, 'average_rating': 4.44}, {'original_title': 'Twilight', 'authors': 'Stephenie Meyer', 'original_publication_year': '2005.0', 'ratings_count': 3866839, 'average_rating': 3.57}, {'original_title': 'To Kill a Mockingbird', 'authors': 'Harper Lee', 'original_publication_year': '1960.0', 'ratings_count': 3198671, 'average_rating': 4.25}, {'original_title': 'The Great Gatsby', 'authors': 'F. Scott Fitzgerald', 'original_publication_year': '1925.0', 'ratings_count': 2683664, 'average_rating': 3.89}, {'original_title': 'The Fault in Our Stars', 'authors': 'John Green', 'original_publication_year': '2012.0', 'ratings_count': 2346404, 'average_rating': 4.26}, {'original_title': 'The Hobbit or There and Back Again', 'authors': 'J.R.R. Tolkien', 'original_publication_year': '1937.0', 'ratings_count': 2071616, 'average_rating': 4.25}, {'original_title': 'The Catcher in the Rye', 'authors': 'J.D. Salinger', 'original_publication_year': '1951.0', 'ratings_count': 2044241, 'average_rating': 3.79}, {'original_title': 'Angels & Demons ', 'authors': 'Dan Brown', 'original_publication_year': '2000.0', 'ratings_count': 2001311, 'average_rating': 3.85}, {'original_title': 'Pride and Prejudice', 'authors': 'Jane Austen', 'original_publication_year': '1813.0', 'ratings_count': 2035490, 'average_rating': 4.24}]\n"
     ]
    }
   ],
   "source": [
    "Authors = Books['authors']\n",
    "OriginalTitle = Books['original_title']\n",
    "OriginalPublicationYear = Books['original_publication_year']\n",
    "\n",
    "RatingsCounttp = Books['ratings_count']\n",
    "RatingsCount = [int(i) for i in RatingsCounttp]\n",
    "AverageRatingtp = Books['average_rating']\n",
    "AverageRating = [float(i) for i in AverageRatingtp]\n",
    "Book_desc = []\n",
    "\n",
    "for i in range (len(OriginalTitle)):\n",
    "    Book_desc.append(dict([(\"original_title\", Books[\"original_title\"][i])]))\n",
    "\n",
    "for i in range (len(OriginalTitle)):\n",
    "    Book_desc[i][\"authors\"] = Authors[i]\n",
    "    Book_desc[i][\"original_publication_year\"] = OriginalPublicationYear[i]\n",
    "    Book_desc[i][\"ratings_count\"] = RatingsCount[i]\n",
    "    Book_desc[i][\"average_rating\"] = AverageRating[i]\n",
    "\n",
    "print(Book_desc[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B2.__ _(5 points)_ Write a function to sort this list of book metadata in descending order of average rating. The function should take the list of metadata dictionaries as an input argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SortingBooks(metadata):\n",
    "    SortedList = sorted(metadata, key=lambda k: k['average_rating'], reverse=True)\n",
    "    return SortedList\n",
    "Book_desc_sorted = SortingBooks(Book_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B3.__ _(10 points)_ Update the function to take two arguments: the list, and an integer value for minimum ratings count. The function should now sort _and_ filter the list, returning a list of books sorted by average rating that have been rated by more than a specified number of users. You can use three different approaches: loops, comprehensions, and the built-in `filter()` function (look up documentation and examples). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'original_title': 'Harry Potter and the Deathly Hallows', 'authors': 'J.K. Rowling, Mary GrandPrÃ©', 'original_publication_year': '2007.0', 'ratings_count': 1746574, 'average_rating': 4.61}, {'original_title': 'Harry Potter and the Half-Blood Prince', 'authors': 'J.K. Rowling, Mary GrandPrÃ©', 'original_publication_year': '2005.0', 'ratings_count': 1678823, 'average_rating': 4.54}, {'original_title': 'Harry Potter and the Prisoner of Azkaban', 'authors': 'J.K. Rowling, Mary GrandPrÃ©, Rufus Beck', 'original_publication_year': '1999.0', 'ratings_count': 1832823, 'average_rating': 4.53}, {'original_title': 'Harry Potter and the Goblet of Fire', 'authors': 'J.K. Rowling, Mary GrandPrÃ©', 'original_publication_year': '2000.0', 'ratings_count': 1753043, 'average_rating': 4.53}, {'original_title': 'Harry Potter and the Order of the Phoenix', 'authors': 'J.K. Rowling, Mary GrandPrÃ©', 'original_publication_year': '2003.0', 'ratings_count': 1735368, 'average_rating': 4.46}, {'original_title': 'The Help', 'authors': 'Kathryn Stockett', 'original_publication_year': '2009.0', 'ratings_count': 1531753, 'average_rating': 4.45}, {'original_title': 'A Game of Thrones', 'authors': 'George R.R. Martin', 'original_publication_year': '1996.0', 'ratings_count': 1319204, 'average_rating': 4.45}, {'original_title': \"Harry Potter and the Philosopher's Stone\", 'authors': 'J.K. Rowling, Mary GrandPrÃ©', 'original_publication_year': '1997.0', 'ratings_count': 4602479, 'average_rating': 4.44}, {'original_title': 'Harry Potter and the Chamber of Secrets', 'authors': 'J.K. Rowling, Mary GrandPrÃ©', 'original_publication_year': '1998.0', 'ratings_count': 1779331, 'average_rating': 4.37}, {'original_title': 'The Book Thief', 'authors': 'Markus Zusak', 'original_publication_year': '2005.0', 'ratings_count': 1159741, 'average_rating': 4.36}]\n"
     ]
    }
   ],
   "source": [
    "def FilteredSortingBooks(metadata, x):\n",
    "    FilteredList = list(filter(lambda m: m['ratings_count'] > x, metadata))\n",
    "    SortedList = sorted(FilteredList, key=lambda m: m['average_rating'], reverse=True)\n",
    "    return SortedList\n",
    "\n",
    "FilteredSortedBookDesc = FilteredSortingBooks(Book_desc, 200000)\n",
    "print(FilteredSortedBookDesc[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bonus:__ _(10 points)_ Use all three approaches to write three different versions of the function. See if you can condense your code into a single line for some of the approaches! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B3.__ _(5 points)_ Why is using a function for this task prudent? What do you think is an acceptable minimum ratings count? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its prudent to use a function with an argument for the minimum rating count because it will exclude titles with few rating counts which usually has unrealistic ratings. The average rating is valid with enough data points. As for high confidence levels, the rating count should be higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem C _(50 points)_\n",
    "\n",
    "This problem deals with finding \"pangrams\" in text. A pangram is a sentence containing all 26 letters of the alphabet. `x` and `y` in the cell below are example sentences, `x` is a pangram, `y` is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"Jim quickly realized that the beautiful gowns are expensive.\"\n",
    "y = \"This sentence is most certainly not a pangram.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C1.__ _(5 points)_ Define a generator function, `indices()`, that takes a string as input and outputs the index numbers where a letter occurs for the first time in the string. [__Hint:__ you can compare letters like numbers. For example, `char >= \"a\"` is a valid conditional statement. You can use this to check whether characters in a string are letters.] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices(input_string):\n",
    "    input_string = input_string.lower()\n",
    "    Alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    IndexList = []\n",
    "    for i in Alphabet:\n",
    "        checkLetter = [pos for pos, char in enumerate(input_string) if char == i]\n",
    "        if checkLetter:\n",
    "            IndexList.append(min(checkLetter))\n",
    "        else:\n",
    "            IndexList.append(\"NA\")\n",
    "        Index_number = IndexList\n",
    "    yield Index_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 'NA',\n",
       " 13,\n",
       " 7,\n",
       " 5,\n",
       " 'NA',\n",
       " 34,\n",
       " 25,\n",
       " 0,\n",
       " 'NA',\n",
       " 'NA',\n",
       " 2,\n",
       " 42,\n",
       " 16,\n",
       " 3,\n",
       " 43,\n",
       " 'NA',\n",
       " 'NA',\n",
       " 12,\n",
       " 9,\n",
       " 'NA',\n",
       " 4,\n",
       " 'NA',\n",
       " 40,\n",
       " 'NA',\n",
       " 'NA']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in indices(\"I love data science and this is a good example\")][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C2.__ _(5 points)_ Define a function, `verify()`, that takes a string as input and uses the `indices()` function to check if the string is a pangram. The output should be boolean `True` or `False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(String_check):\n",
    "    String_check = String_check.lower()\n",
    "    Index_num = [x for x in indices(String_check)][0]\n",
    "    if \"NA\" in Index_num:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"Jim quickly realized that the beautiful gowns are expensive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"This sentence is most certainly not a pangram.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C3:__ _(5 points)_ Write a version of `verify()` named `tiny_verify()` that performs the check in a single line of code, without using `indices()`. [__Hint:__ Use a comprehension.] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiny_verify(inputString):\n",
    "    return not set('abcdefghijklmnopqrstuvwxyz') - set(inputString.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_verify(\"I love data science\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C4.__ _(5 points)_ Modify the `verify()` function to figure out which letters (if any) are missing from a purported pangram. This version should return the list of missing letters instead of a boolean value. [__Hint:__ You can get a string containing all the letters of the alphabet by importing `ascii_lowercase` from the `string` module.] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'f', 'h', 'j', 'k', 'm', 'p', 'q', 'r', 'u', 'w', 'x', 'y', 'z']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def verify2(inputString):\n",
    "    MissingLettersList = []\n",
    "    Alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    inpuString = inputString.lower()\n",
    "    Index_number = [x for x in indices(inputString)][0]\n",
    "    for i in range(len(Alphabet)):\n",
    "        if Index_number[i] == \"NA\":\n",
    "            MissingLettersList.append(Alphabet[i])  \n",
    "    return MissingLettersList\n",
    "\n",
    "verify2(\"I love data science again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C5.__ _(5 points)_ Load and iterated through the collected [list of pangrams](http://clagnut.com/blog/2380/) in `data/pangrams.txt` line by line and determine if they are actually pangrams. Print out any lines that are not actually pangrams, and also the letters that are missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show mangled quartz flip vibe exactly.\n",
      "\n",
      "Unamazingly, this six-word pangram is questionable!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"data/pangrams.txt\", encoding=\"utf8\")\n",
    "FalsePangrams = []\n",
    "\n",
    "def verify(String_check):\n",
    "    String_check = String_check.lower()\n",
    "    Index_num = [x for x in indices(String_check)][0]\n",
    "    if \"NA\" in Index_num:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "with f as file_handle:\n",
    "    for line in file_handle:\n",
    "        if verify(line) == False:\n",
    "            FalsePangrams.append(line)\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C6:__ _(5 points)_ Use the output from the `verify()` function to fix the failed pangrams, and verify that you have fixed them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "FixedPangrams = []\n",
    "for line in FalsePangrams:\n",
    "    for missingchar in verify2(line):\n",
    "        line = line + missingchar\n",
    "    FixedPangrams.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C7.__ _(5 points)_ In the cell below are provided some information about a set of books. Create a data object that holds the book numbers and titles associated to each authors's name. Write this out as a JSON file in the `data/books/` directory using the following schema. \n",
    "\n",
    "```\n",
    "books = {\n",
    "    AuthorName: {\n",
    "        BookNumber: BookTitle,\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 84.txt; Frankenstein, or the Modern Prometheus; Mary Wollstonecraft (Godwin) Shelley\n",
    "# 98.txt; A Tale of Two Cities; Charles Dickens \n",
    "# 161.txt; Sense and Sensibility; Jane Austen\n",
    "# 730.txt; Oliver Twist or the Parish Boy's Progress; Charles Dickens\n",
    "# 768.txt; Wuthering Heights; Emily Brontë\n",
    "# 1322.txt; Leaves of Grass; Walt Whitman\n",
    "# 1342.txt; Pride and Prejudice; Jane Austen\n",
    "# 1400.txt; Great Expectations; Charles Dickens\n",
    "# 2701.txt; Moby Dick; or the Whale; Herman Melville\n",
    "# 4300.txt; Ulysses; James Joyce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "books = {}  \n",
    "books['Mary Wollstonecraft (Godwin) Shelley'] = []  \n",
    "books['Mary Wollstonecraft (Godwin) Shelley'].append({  \n",
    "    'BookNumber': '84',\n",
    "    'BookTitle': 'Frankenstein, or the Modern Prometheus'})\n",
    "\n",
    "books['Charles Dickens'] = []\n",
    "books['Charles Dickens'].append({  \n",
    "    'BookNumber': '98',\n",
    "    'BookTitle': 'A Tale of Two Cities'})\n",
    "\n",
    "books['Charles Dickens'].append({  \n",
    "    'BookNumber': '730',\n",
    "    'BookTitle': \"Oliver Twist or the Parish Boy's Progress\"})\n",
    "\n",
    "books['Charles Dickens'].append({  \n",
    "    'BookNumber': '1400',\n",
    "    'BookTitle': \"Great Expectations\"})\n",
    "\n",
    "books['Jane Austen'] = []\n",
    "books['Jane Austen'].append({  \n",
    "    'BookNumber': '161',\n",
    "    'BookTitle': \"Sense and Sensibility\"})\n",
    "\n",
    "books['Jane Austen'].append({  \n",
    "    'BookNumber': '1342',\n",
    "    'BookTitle': \"Pride and Prejudice\"})\n",
    "\n",
    "books['Emily Brontë'] = []\n",
    "books['Jane Austen'].append({  \n",
    "    'BookNumber': '768',\n",
    "    'BookTitle': \"Wuthering Heights\"})\n",
    "\n",
    "books['Walt Whitman'] = []\n",
    "books['Walt Whitman'].append({  \n",
    "    'BookNumber': '1322',\n",
    "    'BookTitle': \"Leaves of Grass\"})\n",
    "\n",
    "books['Herman Melville'] = []\n",
    "books['Herman Melville'].append({  \n",
    "    'BookNumber': '2701',\n",
    "    'BookTitle': \"Moby Dick, or the Whale\"})\n",
    "\n",
    "books['James Joyce'] = []\n",
    "books['James Joyce'].append({  \n",
    "    'BookNumber': '4300',\n",
    "    'BookTitle': \"Ulysses\"})\n",
    "\n",
    "with open('data/books/BooksInfo.txt', 'w') as outfile:  \n",
    "    json.dump(books, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C8.__ _(5 points)_ Write a function, `get_pangrams()`, that takes a book number and outputs a list of the book's pangram sentences and the total number of sentences in the book. You will need to use the `re` (regular expressions) module to split the book text into sentences using the `re.split(pattern, string)` function. The pattern you will need is `\"[\\.\\?\\!][^a-zA-Z]\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_pangrams(Book_Num):\n",
    "    \n",
    "    Path = \"data/books/\"\n",
    "    Path = Path + str(Book_Num) + \".txt\"\n",
    "    sentences = []\n",
    "    pangram = []\n",
    "    \n",
    "    with open(Path, \"r\") as file_handle:\n",
    "        all_text = file_handle.read()\n",
    "    sentences_newline = re.split(\"[\\.\\?\\!][^a-zA-Z]\", all_text)\n",
    "    for i in sentences_newline:\n",
    "        sentences.append(i.strip('\\n'))\n",
    "    for elements in sentences:\n",
    "        pangram.append(verify(str(elements)))\n",
    "    Panagram_Num = sum(pangram)\n",
    "    return([Panagram_Num, len(sentences)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C9.__ _(10 points)_ Determine who is the pangrammiest author and what the pangrammiest book is, as determined by pangrams per sentence. [__Hint:__ Use `defaultdict`s to create \"pangrams by author\" and \"pangrams by book\" objects.] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'Mary Wollstonecraft (Godwin) Shelley': [0.0], 'Charles Dickens': [0.00011811953697141507, 9.492168960607498e-05, 0.0], 'Jane Austen': [0.0, 0.00042005040604872583], 'Emily Brontë': [0.00013795006207752792], 'Walt Whitman': [0.00233160621761658], 'Herman Melville': [0.00038387715930902113], 'James Joyce': [0.00044682752457551384]})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def indices(input_string):\n",
    "    input_string = input_string.lower()\n",
    "    Alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    IndexList = []\n",
    "    for i in Alphabet:\n",
    "        checkLetter = [pos for pos, char in enumerate(input_string) if char == i]\n",
    "        if checkLetter:\n",
    "            IndexList.append(min(checkLetter))\n",
    "        else:\n",
    "            IndexList.append(\"NA\")\n",
    "        Index_number = IndexList\n",
    "    yield Index_number\n",
    "\n",
    "#pangrams per sentence for each book\n",
    "authors_pangrams = [(\"Mary Wollstonecraft (Godwin) Shelley\", get_pangrams(84)[0]/get_pangrams(84)[1]), \n",
    "        (\"Charles Dickens\", get_pangrams(98)[0]/get_pangrams(98)[1]), \n",
    "        (\"Jane Austen\", get_pangrams(161)[0]/get_pangrams(161)[1]), \n",
    "        (\"Charles Dickens\", get_pangrams(730)[0]/get_pangrams(730)[1]), \n",
    "        (\"Emily Brontë\", get_pangrams(768)[0]/get_pangrams(768)[1]), \n",
    "        (\"Walt Whitman\", get_pangrams(1322)[0]/get_pangrams(1322)[1]), \n",
    "        (\"Jane Austen\", get_pangrams(1342)[0]/get_pangrams(1342)[1]), \n",
    "        (\"Charles Dickens\", get_pangrams(1400)[0]/get_pangrams(1400)[1]), \n",
    "        (\"Herman Melville\", get_pangrams(2701)[0]/get_pangrams(2701)[1]), \n",
    "        (\"James Joyce\", get_pangrams(4300)[0]/get_pangrams(4300)[1])]\n",
    "#exact values of given panagrams above ^^ will give an error not the exact number\n",
    "\n",
    "#pangrams per sentence for each author\n",
    "pangrams_by_author = defaultdict(list)\n",
    "for authors, authors_pangrams in authors_pangrams:\n",
    "    pangrams_by_author[authors].append(authors_pangrams)    \n",
    "print(pangrams_by_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mary Wollstonecraft (Godwin) Shelley': 0.0, 'Charles Dickens': 0.00021304122657749006, 'Jane Austen': 0.00042005040604872583, 'Emily Brontë': 0.00013795006207752792, 'Walt Whitman': 0.00233160621761658, 'Herman Melville': 0.00038387715930902113, 'James Joyce': 0.00044682752457551384}\n"
     ]
    }
   ],
   "source": [
    "#pangrams per sentence for each author:\n",
    "sumof = {j: sum(k) for (j, k) in pangrams_by_author.items()}\n",
    "print(sumof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walt Whitman 0.00233160621761658\n",
      "James Joyce 0.00044682752457551384\n",
      "Jane Austen 0.00042005040604872583\n",
      "Herman Melville 0.00038387715930902113\n",
      "Charles Dickens 0.00021304122657749006\n",
      "Emily Brontë 0.00013795006207752792\n",
      "Mary Wollstonecraft (Godwin) Shelley 0.0\n"
     ]
    }
   ],
   "source": [
    "#author panagrams from the most to the least:\n",
    "for i in sorted(sumof,key=sumof.get, reverse=True):\n",
    "  print(i, sumof[i])\n",
    "\n",
    "#pangrams per sentence for each book:\n",
    "books_pangrams = [(\"Frankenstein, or the Modern Prometheus\", get_pangrams(84)[0]/get_pangrams(84)[1]), \n",
    "        (\"A Tale of Two Cities\", get_pangrams(98)[0]/get_pangrams(98)[1]), \n",
    "        (\"Sense and Sensibility\", get_pangrams(161)[0]/get_pangrams(161)[1]), \n",
    "        (\"Oliver Twist or the Parish Boy's Progress\", get_pangrams(730)[0]/get_pangrams(730)[1]), \n",
    "        (\"Wuthering Heights\", get_pangrams(768)[0]/get_pangrams(768)[1]), \n",
    "        (\"Leaves of Grass\", get_pangrams(1322)[0]/get_pangrams(1322)[1]), \n",
    "        (\"Pride and Prejudice\", get_pangrams(1342)[0]/get_pangrams(1342)[1]), \n",
    "        (\"Great Expectations\", get_pangrams(1400)[0]/get_pangrams(1400)[1]), \n",
    "        (\"Moby Dick, or the Whale\", get_pangrams(2701)[0]/get_pangrams(2701)[1]), \n",
    "        (\"Ulysses\", get_pangrams(4300)[0]/get_pangrams(4300)[1])]\n",
    "#exact values of given panagrams above ^^ will give an error not the exact number\n",
    "\n",
    "pangrams_each_book = defaultdict(list)\n",
    "\n",
    "for title, books_pangrams in books_pangrams:\n",
    "    pangrams_each_book[title].append(books_pangrams)\n",
    "    \n",
    "print(pangrams_each_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most to least panagrams in each book\n",
    "for c in sorted(pangrams_each_book, key=pangrams_each_book.get, reverse=True):\n",
    "  print(c, pangrams_each_book[c])\n",
    "#Blank output? wont print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bonus:__ _(5 points)_ Print out the most efficient pangram and its author and book, as determined by fewest characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
